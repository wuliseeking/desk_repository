# desk_repository
该脚本主要实现根据一个种子URL，下载 【从这个种子URL起  每个下载页面中包含的】  所有符合要求的URL,但并未保存下载的URL。
符合的要求包含: 
(1)user_agent是否被允许下载这个URL 
(2)该URL是否满足用户设置的正则表达式 
(3)该URL是否达到限制的爬取深度
(4)下载的URL是否达到设置的最大限制数

内部预防隐患的功能点有：
(1)避免下载过于频繁导致的封号设置了同域名的下载时间间隔
(2)避免某些用户代理被禁止请求设置了用户代理
(3)避免爬取某用户代理不被允许爬取的页面解析了robots.txt文件规则做判断
(4)避免在一个页面中进入无休止的链接爬取设置了最大爬取深度，
(5)避免重复爬取已下载的URL设置了记录所有URL的变量
(6)为合理控制下载规模设置了最大下载数
(7)避免页面中的URL为相对链接将其转化为绝对URL
(8)避免由于服务器端响应缓慢、响应繁忙等原因导致下载失败设置了重试下载次数
(9)避免一个URL的下载错误使程序终止使用了try...except 跳过
